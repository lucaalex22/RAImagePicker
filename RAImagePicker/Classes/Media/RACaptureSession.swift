////
////  RACaptureSession.swift
////  RAImagePicker
////
////  Created by Rashed Al Lahaseh on 12/1/17.
////
//
//import UIKit
//import Foundation
//import AVFoundation
//import Photos
//
///*
//    Progress and States of Capturing Photo Process Delegation
//*/
//protocol RACaptureSessionPhotoCapturingDelegate : class {
//
//    // Called as soon as the photo taken [used for UI update]
//    func captureSession(_ session: RACaptureSession, willCapturePhotoWith settings: AVCapturePhotoSettings)
//
//    // Captured photo and ready to use it
//    func captureSession(_ session: RACaptureSession, didCapturePhotoData: Data, with settings: AVCapturePhotoSettings)
//
//    // Failed to capture photo
//    func captureSession(_ session: RACaptureSession, didFailCapturingPhotoWith error: Error)
//
//    // Control number of live photos [inProgressLivePhotoCapturesCount: current count]
//    func captureSessionDidChangeNumberOfProcessingLivePhotos(_ session: RACaptureSession)
//}
//
///*
//    Progress and States of Recording Video Process Delegation
// */
//protocol RACaptureSessionVideoRecordingDelegate : class {
//
//    // Video file recording output has been added to the session
//    func captureSessionDidBecomeReadyForVideoRecording(_ session: RACaptureSession)
//
//    // Started recording
//    func captureSessionDidStartVideoRecording(_ session: RACaptureSession)
//
//    // Cancel recording
//    func captureSessionDidCancelVideoRecording(_ session: RACaptureSession)
//
//    // Failed recording
//    func captureSessionDid(_ session: RACaptureSession, didFailVideoRecording error: Error)
//
//    // Successfully finshed recording
//    func captureSessionDid(_ session: RACaptureSession, didFinishVideoRecording videoURL: URL)
//
//    // Get interruption due to a system thing, so it finshed premturely
//    func captureSessionDid(_ session: RACaptureSession, didInterruptVideoRecording videoURL: URL, reason: Error)
//}
//
//protocol RACaptureSessionDelegate : class {
//
//    // Successfully configured and started running
//    func captureSessionDidResume(_ session: RACaptureSession)
//
//    // Session was created and configured but failed [eg: I/O could not be added, etc ...]
//    func captureSessionDidFailConfiguringSession(_ session: RACaptureSession)
//
//    // Manually suspended
//    func captureSessionDidSuspend(_ session: RACaptureSession)
//
//    // Session was running but did fail due to any AVError reason.
//    func captureSession(_ session: RACaptureSession, didFail error: AVError)
//
//    // Session was interrupted [eg: phone call, starts an audio using control center, etc ...]
//    func captureSession(_ session: RACaptureSession, wasInterrupted reason: AVCaptureSession.InterruptionReason)
//
//    // Interruption is ended and the session was automatically resumed
//    func captureSessionInterruptionDidEnd(_ session: RACaptureSession)
//
//    // Failed get authorization status [eg: user denied access to video device]
//    func captureSession(_ session: RACaptureSession, authorizationStatusFailed status: AVAuthorizationStatus)
//
//    // Granted authorization status [eg: user grants access to video device]
//    func captureSession(_ session: RACaptureSession, authorizationStatusGranted status: AVAuthorizationStatus)
//}
//
///*
//    Manages AVCaptureSession
// */
//final class RACaptureSession : NSObject {
//
//    // MARK: - Private Methods
//
//    // Queue which communicate with methods and other sessions through it
//    fileprivate let sessionQueue = DispatchQueue(label: "session_queue", attributes: [], target: nil)
//    fileprivate var setupResult: SessionSetupResult = .success
//    fileprivate var videoDeviceInput: AVCaptureDeviceInput!
//    fileprivate lazy var videoDeviceDiscoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [AVCaptureDevice.DeviceType.builtInWideAngleCamera, AVCaptureDevice.DeviceType.builtInDuoCamera], mediaType: AVMediaType.video, position: .unspecified)
//    fileprivate var videoDataOutput: AVCaptureVideoDataOutput?
//    fileprivate let videoOutpuSampleBufferDelegate = RAVideoOutputSampleBufferDelegate()
//
//    fileprivate enum SessionSetupResult {
//        case success
//        case notAuthorized
//        case configurationFailed
//    }
//
//    enum SessionPresetConfiguration {
//        case photos, livePhotos
//        case videos
//    }
//
//    weak var delegate: RACaptureSessionDelegate?
//
//    let session = AVCaptureSession()
//    var isSessionRunning = false
//    weak var previewLayer: AVCaptureVideoPreviewLayer?
//
//    var presetConfiguration: SessionPresetConfiguration = .photos
//
//    // Set video orientation that matches app UI.
//    // Note: using this method perofre running the session, otherwise use "updateVideoOrientation()" method.
//    var videoOrientation: AVCaptureVideoOrientation = .portrait
//
//    // Updates on video output
//    func updateVideoOrientation(new: AVCaptureVideoOrientation) {
//
//        videoOrientation = new
//        // Change orientation on all outputs
//        self.previewLayer?.connection?.videoOrientation = new
//
//        // TODO: Missing
//        // Note: - Update orientation of video data output is blinking a bit [which is uggly]
//        //       - Adding updates into a configuration block make the lag worse
//        sessionQueue.async {
//            // Disconnected device let the video data-ouput connection orientation reset
//            // So get a new proper value
//            self.videoDataOutput?.connection(with: AVMediaType.video)?.videoOrientation = new
//        }
//    }
//
//    // MARK: - Video Recoding
//
//    weak var videoRecordingDelegate: RACaptureSessionVideoRecordingDelegate?
//    fileprivate var videoFileOutput: AVCaptureMovieFileOutput?
//    fileprivate var videoCaptureDelegate: RAVideoCaptureDelegate?
//
//    var isReadyForVideoRecording: Bool {
//        return videoFileOutput != nil
//    }
//    var isRecordingVideo: Bool {
//        return videoFileOutput?.isRecording ?? false
//    }
//    // Latest captured image
//    var latestVideoBufferImage: UIImage? {
//        return videoOutpuSampleBufferDelegate.latestImage
//    }
//
//    // MARK: - Photo Capturing
//
//    fileprivate let photoOutput = AVCapturePhotoOutput()
//    fileprivate var inProgressPhotoCaptureDelegates = [Int64 : RAPhotoCaptureDelegate]()
//    fileprivate(set) var inProgressLivePhotoCapturesCount = 0 // Number of currently processing live photos
//    weak var photoCapturingDelegate: RACaptureSessionPhotoCapturingDelegate?
//
//    enum LivePhotoMode {
//        case on
//        case off
//    }
//
//    // MARK: - Public Methods
//
//    func prepare() {
//
//        // Video Authorization Status, video access is required and audio is optional
//        let mediaType = AVMediaType.video
//        switch AVCaptureDevice.authorizationStatus(for: mediaType) {
//        case .authorized:
//            // Granted access to the camera
//            break
//
//        case .notDetermined:
//            // Has not been presented with the option to grant video access
//            sessionQueue.suspend()
//            AVCaptureDevice.requestAccess(for: AVMediaType.video, completionHandler: { [capturedSelf = self] granted in
//                if granted {
//                    DispatchQueue.main.async {
//                        capturedSelf.delegate?.captureSession(capturedSelf, authorizationStatusGranted: .authorized)
//                    }
//                }
//                else {
//                    capturedSelf.setupResult = .notAuthorized
//                }
//                capturedSelf.sessionQueue.resume()
//            })
//
//        default:
//            // Denied access to the camera
//            setupResult = .notAuthorized
//        }
//
//        /*
//            Setup capture session
//                - In general it is not safe to mutate an AVCaptureSession or any of its inputs, outputs, or connections from multiple threads at the same time.
//
//            Why not do all of this on the main queue?
//                - Because AVCaptureSession.startRunning() is a blocking call which can take a long time. We dispatch session setup to the sessionQueue so that the main queue isn't blocked, which keeps the UI responsive.
//         */
//        sessionQueue.async { [capturedSelf = self] in
//            capturedSelf.configureSession()
//        }
//    }
//
//    func resume() {
//        sessionQueue.async {
//
//            guard self.isSessionRunning == false
//                else {
//                return print("Capture Session: -WARNING- trying to resume already running session")
//            }
//
//            switch self.setupResult {
//            case .success:
//                // Only setup observers and start the session running if setup succeeded.
//                self.addObservers()
//                self.session.startRunning()
//                self.isSessionRunning = self.session.isRunning
//                /*
//                    We are not calling the delegate here explicitly, because we are observing "running" KVO on session itself.
//                 */
//
//            case .notAuthorized:
//                print("Capture Session: not authorized")
//                DispatchQueue.main.async { [weak self] in
//                    let status = AVCaptureDevice.authorizationStatus(for: AVMediaType.video)
//                    self?.delegate?.captureSession(self!, authorizationStatusFailed: status)
//                }
//
//            case .configurationFailed:
//                print("Capture Session: configuration failed")
//
//                DispatchQueue.main.async { [weak self] in
//                    self?.delegate?.captureSessionDidFailConfiguringSession(self!)
//                }
//            }
//        }
//    }
//
//    func suspend() {
//
//        guard setupResult == .success
//            else {
//            return
//        }
//
//        /*
//            We need to capture self in order to postpone deallocation while session is properly stopped and cleaned up
//         */
//        sessionQueue.async { [capturedSelf = self] in
//
//            guard self.isSessionRunning == true else {
//                return print("Capture Session: -WARNING- trying to suspend non running session")
//            }
//
//            /*
//                We are not calling delegate from here because, we are KVOing "isRunning" on session itself so it's called from there
//             */
//            capturedSelf.session.stopRunning()
//            capturedSelf.isSessionRunning = self.session.isRunning
//            capturedSelf.removeObservers()
//        }
//    }
//
//    // MARK: - Private Methods
//
//    /*
//        Configuring Session:
//            1. Adds Video Input
//            2. Adds Video Output [Recording Videos]
//            3. Adds Audio Input  [Video Recording with Audio]
//            4. Adds Photo Ouput  [Capturing Photos]
//     */
//    private func configureSession() {
//
//        guard setupResult == .success else {
//            return
//        }
//        print("Capture Session: configuring - adding video input")
//        session.beginConfiguration()
//        switch presetConfiguration {
//        case .livePhotos, .photos:
//            session.sessionPreset = AVCaptureSession.Preset.photo
//        case .videos:
//            session.sessionPreset = AVCaptureSession.Preset.high
//        }
//
//        // 1. Adds Video Input
//        do {
//            var defaultVideoDevice: AVCaptureDevice?
//
//            // Choose the back dual camera if available, otherwise default to a wide angle camera.
//            if let dualCameraDevice = AVCaptureDevice.default(AVCaptureDevice.DeviceType.builtInDuoCamera, for: AVMediaType.video, position: .back) {
//                defaultVideoDevice = dualCameraDevice
//            }
//            else if let backCameraDevice = AVCaptureDevice.default(AVCaptureDevice.DeviceType.builtInWideAngleCamera, for: AVMediaType.video, position: .back) {
//                // If the back dual camera is not available, default to the back wide angle camera.
//                defaultVideoDevice = backCameraDevice
//            }
//            else if let frontCameraDevice = AVCaptureDevice.default(AVCaptureDevice.DeviceType.builtInWideAngleCamera, for: AVMediaType.video, position: .front) {
//                // In some cases where users break their phones, the back wide angle camera is not available. In this case, we should default to the front wide angle camera.
//                defaultVideoDevice = frontCameraDevice
//            }
//            else {
//                print("Capture Session: could not create capture device")
//                setupResult = .configurationFailed
//                session.commitConfiguration()
//                return
//            }
//
//            let videoDeviceInput = try AVCaptureDeviceInput(device: defaultVideoDevice!)
//
//            if session.canAddInput(videoDeviceInput) {
//                session.addInput(videoDeviceInput)
//
//                self.videoDeviceInput = videoDeviceInput
//
//                DispatchQueue.main.async {
//                    /*
//                        Why are we dispatching this to the main queue?
//                            - Because AVCaptureVideoPreviewLayer is the backing layer for PreviewView and UIView
//                                can only be manipulated on the main thread.
//
//                        Note: As an exception to the above rule, it is not necessary to serialize video orientation changes on the AVCaptureVideoPreviewLayer’s connection with other session manipulation.
//                     */
//                    self.previewLayer?.connection?.videoOrientation = self.videoOrientation
//                }
//            }
//            else {
//                print("Capture Session: could not add video device input to the session")
//                setupResult = .configurationFailed
//                session.commitConfiguration()
//                return
//            }
//        }
//        catch {
//            print("Capture Session: could not create video device input: \(error)")
//            setupResult = .configurationFailed
//            session.commitConfiguration()
//            return
//        }
//
//        // 2. Adds Video Output [Recording Videos]
//        if presetConfiguration == .videos {
//
//            /*
//                Caputre Session cannot support [Live Photo/Movie File Output/Video Data Output] at the same time if your capture session includes an AVCaptureMovieFileOutput, then isLivePhotoCaptureSupported property becomes false
//             */
//            print("Capture Session: configuring - adding movie file input")
//            let movieFileOutput = AVCaptureMovieFileOutput()
//            if self.session.canAddOutput(movieFileOutput) {
//                self.session.addOutput(movieFileOutput)
//                self.videoFileOutput = movieFileOutput
//
//                DispatchQueue.main.async { [weak self] in
//                    self?.videoRecordingDelegate?.captureSessionDidBecomeReadyForVideoRecording(self!)
//                }
//            }
//            else {
//                print("capture session: could not add video output to the session")
//                setupResult = .configurationFailed
//                session.commitConfiguration()
//                return
//            }
//        }
//        if presetConfiguration == .livePhotos || presetConfiguration == .videos {
//
//            print("Capture Session: configuring - adding audio input")
//            // Add audio input, if fails no need to fail whole configuration
//            do {
//                let audioDevice = AVCaptureDevice.default(for: AVMediaType.audio)
//                let audioDeviceInput = try AVCaptureDeviceInput(device: audioDevice!)
//
//                if session.canAddInput(audioDeviceInput) {
//                    session.addInput(audioDeviceInput)
//                }
//                else {
//                    print("Capture Session: could not add audio device input to the session")
//                }
//            }
//            catch {
//                print("Capture Session: could not create audio device input: \(error)")
//            }
//        }
//
//        if presetConfiguration == .livePhotos || presetConfiguration == .photos || presetConfiguration == .videos
//        {
//            // Add photo output.
//            print("Capture Session: configuring - adding photo output")
//
//            if session.canAddOutput(photoOutput) {
//                session.addOutput(photoOutput)
//                photoOutput.isHighResolutionCaptureEnabled = true
//
//                //enable live photos only if we intend to use it explicitly
//                if presetConfiguration == .livePhotos {
//                    photoOutput.isLivePhotoCaptureEnabled = photoOutput.isLivePhotoCaptureSupported
//                    if photoOutput.isLivePhotoCaptureSupported == false {
//                        print("Capture Session: configuring - requested live photo mode is not supported by the device")
//                    }
//                }
//                print("Capture Session: configuring - live photo mode is \(photoOutput.isLivePhotoCaptureEnabled ? "enabled" : "disabled")")
//            }
//            else {
//                print("Capture Session: could not add photo output to the session")
//                setupResult = .configurationFailed
//                session.commitConfiguration()
//                return
//            }
//        }
//
//        if presetConfiguration != .videos {
//            /*
//                Adds Video Output, use this to capture last video sample that is used when blurring video layer.
//                    Ex: When capture session is suspended, Changing configuration, etc...
//
//                Note: Video Data Output, can not be connected at the same time as video file output!
//             */
//            videoDataOutput = AVCaptureVideoDataOutput()
//            if session.canAddOutput(videoDataOutput!) {
//                session.addOutput(videoDataOutput!)
//                videoDataOutput!.alwaysDiscardsLateVideoFrames = true
//                videoDataOutput!.setSampleBufferDelegate(videoOutpuSampleBufferDelegate, queue: videoOutpuSampleBufferDelegate.processQueue)
//
//                if let connection = videoDataOutput!.connection(with: AVMediaType.video) {
//                    connection.videoOrientation = self.videoOrientation
//                    connection.automaticallyAdjustsVideoMirroring = false
//                }
//            }
//            else {
//                print("Capture Session: -WARNING- could not add video data output to the session")
//            }
//        }
//
//        session.commitConfiguration()
//    }
//
//    // MARK: - KVO and Notifications
//
//    private var sessionRunningObserveContext = 0
//    private var addedObservers = false
//
//    private func addObservers() {
//
//        guard addedObservers == false else { return }
//
//        session.addObserver(self, forKeyPath: "running", options: .new, context: &sessionRunningObserveContext)
//        NotificationCenter.default.addObserver(self, selector: #selector(subjectAreaDidChange), name: Notification.Name("AVCaptureDeviceSubjectAreaDidChangeNotification"), object: videoDeviceInput.device)
//        NotificationCenter.default.addObserver(self, selector: #selector(sessionRuntimeError), name: Notification.Name("AVCaptureSessionRuntimeErrorNotification"), object: session)
//
//        /*
//            A session can only run when the app is full screen. It will be interrupted in a multi-app layout, introduced in iOS 9, see also the documentation of AVCaptureSessionInterruptionReason. Add observers to handle these session interruptions and show a preview is paused message. See the documentation of AVCaptureSessionWasInterruptedNotification for other interruption reasons.
//         */
//        NotificationCenter.default.addObserver(self, selector: #selector(sessionWasInterrupted), name: Notification.Name("AVCaptureSessionWasInterruptedNotification"), object: session)
//        NotificationCenter.default.addObserver(self, selector: #selector(sessionInterruptionEnded), name: Notification.Name("AVCaptureSessionInterruptionEndedNotification"), object: session)
//
//        addedObservers = true
//    }
//    private func removeObservers() {
//
//        guard addedObservers == true else { return }
//
//        NotificationCenter.default.removeObserver(self)
//        session.removeObserver(self, forKeyPath: "running", context: &sessionRunningObserveContext)
//
//        addedObservers = false
//    }
//
//    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey : Any]?, context: UnsafeMutableRawPointer?) {
//        if context == &sessionRunningObserveContext {
//            let newValue = change?[.newKey] as AnyObject?
//            guard let isSessionRunning = newValue?.boolValue else { return }
//
//            DispatchQueue.main.async { [capturedSelf = self] in
//                print("Capture Session: is running - \(isSessionRunning)")
//                if isSessionRunning {
//                    self.delegate?.captureSessionDidResume(capturedSelf)
//                }
//                else {
//                    self.delegate?.captureSessionDidSuspend(capturedSelf)
//                }
//            }
//        }
//        else {
//            super.observeValue(forKeyPath: keyPath, of: object, change: change, context: context)
//        }
//    }
//    @objc func sessionRuntimeError(notification: NSNotification) {
//        guard let errorValue = notification.userInfo?[AVCaptureSessionErrorKey] as? NSError else {
//            return
//        }
//
//        let error = AVError(_nsError: errorValue)
//        print("Capture Session: runtime error: \(error)")
//
//        /*
//            Automatically try to restart the session running if media services were reset and the last start running succeeded. Otherwise, enable the user to try to resume the session running.
//         */
//        if error.code == .mediaServicesWereReset {
//            sessionQueue.async { [capturedSelf = self] in
//                if capturedSelf.isSessionRunning {
//                    capturedSelf.session.startRunning()
//                    capturedSelf.isSessionRunning = capturedSelf.session.isRunning
//                }
//                else {
//                    DispatchQueue.main.async {
//                        capturedSelf.delegate?.captureSession(capturedSelf, didFail: error)
//                    }
//                }
//            }
//        }
//        else {
//            DispatchQueue.main.async { [weak self] in
//                self?.delegate?.captureSession(self!, didFail: error)
//            }
//        }
//    }
//    @objc func sessionWasInterrupted(notification: NSNotification) {
//        /*
//            In some scenarios we want to enable the user to resume the session running. For example, if music playback is initiated via control center while using AVCam, then the user can let AVCam resume the session running, which will stop music playback. Note that stopping music playback in control center will not automatically resume the session running. Also note that it is not always possible to resume, see "resumeInterruptedSession(_:)".
//         */
//        if let userInfoValue = notification.userInfo?[AVCaptureSessionInterruptionReasonKey] as AnyObject?, let reasonIntegerValue = userInfoValue.integerValue, let reason = AVCaptureSession.InterruptionReason(rawValue: reasonIntegerValue) {
//            print("Capture Session: session was interrupted with reason \(reason)")
//            DispatchQueue.main.async { [weak self] in
//                self?.delegate?.captureSession(self!, wasInterrupted: reason)
//            }
//        }
//        else {
//            print("Capture Session: session was interrupted due to unknown reason")
//        }
//    }
//
//    @objc func sessionInterruptionEnded(notification: NSNotification) {
//
//        print("Capture Session: interruption ended")
//        /*
//            Automatically called when interruption is done and session is automatically resumed. Delegate should know that this happened so the UI can be updated
//         */
//        DispatchQueue.main.async { [weak self] in
//            self?.delegate?.captureSessionInterruptionDidEnd(self!)
//        }
//    }
//}
//
//// MARK: - Change Camera Extension
//extension RACaptureSession {
//
//    @objc func subjectAreaDidChange(notification: NSNotification) {
//    }
//
//    func changeCamera(completion: (() -> Void)?) {
//
//        guard setupResult == .success else {
//            return print("Capture Session: -WARNING- trying to change camera but capture session setup failed")
//        }
//
//        sessionQueue.async { [unowned self] in
//            let currentVideoDevice = self.videoDeviceInput.device
//            let currentPosition = currentVideoDevice.position
//
//            let preferredPosition: AVCaptureDevice.Position
//            let preferredDeviceType: AVCaptureDevice.DeviceType
//
//            switch currentPosition {
//            case .unspecified, .front:
//                preferredPosition = .back
//                preferredDeviceType = AVCaptureDevice.DeviceType.builtInDuoCamera
//
//            case .back:
//                preferredPosition = .front
//                preferredDeviceType = AVCaptureDevice.DeviceType.builtInWideAngleCamera
//            }
//
//            let devices = self.videoDeviceDiscoverySession.devices
//            var newVideoDevice: AVCaptureDevice? = nil
//
//            // First, look for a device with both the preferred position and device type. Otherwise, look for a device with only the preferred position.
//            if let device = devices.filter({ $0.position == preferredPosition && $0.deviceType == preferredDeviceType }).first {
//                newVideoDevice = device
//            }
//            else if let device = devices.filter({ $0.position == preferredPosition }).first {
//                newVideoDevice = device
//            }
//
//            if let videoDevice = newVideoDevice {
//                do {
//                    let videoDeviceInput = try AVCaptureDeviceInput(device: videoDevice)
//
//                    self.session.beginConfiguration()
//
//                    // Remove the existing device input first, since using the front and back camera simultaneously is not supported.
//                    self.session.removeInput(self.videoDeviceInput)
//
//                    if self.session.canAddInput(videoDeviceInput) {
//                        NotificationCenter.default.removeObserver(self, name: Notification.Name("AVCaptureDeviceSubjectAreaDidChangeNotification"), object: currentVideoDevice)
//                        NotificationCenter.default.addObserver(self, selector: #selector(self.subjectAreaDidChange), name: Notification.Name("AVCaptureDeviceSubjectAreaDidChangeNotification"), object: videoDeviceInput.device)
//
//                        self.session.addInput(videoDeviceInput)
//                        self.videoDeviceInput = videoDeviceInput
//                    }
//                    else {
//                        self.session.addInput(self.videoDeviceInput);
//                    }
//
//                    if let connection = self.videoFileOutput?.connection(with: AVMediaType.video) {
//                        if connection.isVideoStabilizationSupported {
//                            connection.preferredVideoStabilizationMode = .auto
//                        }
//                    }
//
//                    /*
//                        Set Live Photo capture enabled if it is supported. When changing cameras, the "isLivePhotoCaptureEnabled" property of the AVCapturePhotoOutput gets set to NO when a video device is disconnected from the session. After the new video device is added to the session, re-enable Live Photo capture on the AVCapturePhotoOutput if it is supported.
//                     */
//                    self.photoOutput.isLivePhotoCaptureEnabled = self.photoOutput.isLivePhotoCaptureSupported && self.presetConfiguration == .livePhotos;
//
//                    /*
//                        When Device is Disconnected:
//                            - Video Data Output connection orientation is reset, so we need to set to new proper value
//                            - Video Mirroring is set to true if camera is front, make sure we use no mirroring
//                     */
//                    if let videoDataOutputConnection = self.videoDataOutput?.connection(with: AVMediaType.video) {
//                        videoDataOutputConnection.videoOrientation = self.videoOrientation
//                        if videoDataOutputConnection.isVideoMirroringSupported {
//                            videoDataOutputConnection.isVideoMirrored = true
//                        }
//                        else {
//                            print("Capture Session: -WARNING- video mirroring on video data output is not supported")
//                        }
//
//                    }
//                    self.session.commitConfiguration()
//                    DispatchQueue.main.async {
//                        completion?()
//                    }
//                }
//                catch {
//                    print("Error occured while creating video device input: \(error)")
//                }
//            }
//        }
//    }
//}
//
//// MARK: - Capture Photos Extension
//extension RACaptureSession {
//
//    func capturePhoto(livePhotoMode: LivePhotoMode, saveToPhotoLibrary: Bool) {
//        /*
//            Retrieve the video preview layer's video orientation on the main queue before entering the session queue. We do this to ensure UI elements are accessed on the main thread and session configuration is done on the session queue.
//         */
//        guard let videoPreviewLayerOrientation = previewLayer?.connection?.videoOrientation else {
//            return print("Capture Session: -WARNING- trying to capture a photo but no preview layer is set")
//        }
//
//        sessionQueue.async {
//            // Update the photo output's connection to match the video orientation of the video preview layer.
//            if let photoOutputConnection = self.photoOutput.connection(with: AVMediaType.video) {
//                photoOutputConnection.videoOrientation = videoPreviewLayerOrientation
//            }
//
//            // Capture a JPEG photo with flash set to auto and high resolution photo enabled.
//            let photoSettings = AVCapturePhotoSettings()
//            photoSettings.flashMode = .auto
//            photoSettings.isHighResolutionPhotoEnabled = true
//
//            // TODO: Missing - "previewPhotoFormat" Preview Photo/Thumbnail
//            if #available(iOS 11.0, *) {
//                if photoSettings.availableEmbeddedThumbnailPhotoCodecTypes.count > 0 {
//                    let previewPixelType = photoSettings.availablePreviewPhotoPixelFormatTypes.first!
//                    let previewFormat = [kCVPixelBufferPixelFormatTypeKey as String: previewPixelType,
//                                         kCVPixelBufferWidthKey as String: 200,
//                                         kCVPixelBufferHeightKey as String: 200,
//                                         ]
//                    photoSettings.previewPhotoFormat = previewFormat
//                }
//            }
//
//            if livePhotoMode == .on {
//                if self.presetConfiguration == .livePhotos && self.photoOutput.isLivePhotoCaptureSupported {
//                    let livePhotoMovieFileName = NSUUID().uuidString
//                    let livePhotoMovieFilePath = (NSTemporaryDirectory() as NSString).appendingPathComponent((livePhotoMovieFileName as NSString).appendingPathExtension("mov")!)
//                    photoSettings.livePhotoMovieFileURL = URL(fileURLWithPath: livePhotoMovieFilePath)
//                }
//                else {
//                    print("Capture Session: -WARNING- trying to capture live photo but it's not supported by current configuration, capturing regular photo instead")
//                }
//            }
//
//            // Useing separate object for the photo capture delegate to isolate each capture life cycle.
//            let photoCaptureDelegate = RAPhotoCaptureDelegate(with: photoSettings, willCapturePhotoAnimation: {
//                DispatchQueue.main.async { [unowned self] in
//                    self.photoCapturingDelegate?.captureSession(self, willCapturePhotoWith: photoSettings)
//                }
//            }, capturingLivePhoto: { capturing in
//                /* Because Live Photo captures can overlap, we need to keep track of the number of in progress Live Photo captures to ensure that the Live Photo label stays visible during these captures.
//                 */
//                self.sessionQueue.async { [unowned self] in
//                    if capturing {
//                        self.inProgressLivePhotoCapturesCount += 1
//                    }
//                    else {
//                        self.inProgressLivePhotoCapturesCount -= 1
//                    }
//
//                    let inProgressLivePhotoCapturesCount = self.inProgressLivePhotoCapturesCount
//                    DispatchQueue.main.async { [unowned self] in
//                        if inProgressLivePhotoCapturesCount >= 0 {
//                            self.photoCapturingDelegate?.captureSessionDidChangeNumberOfProcessingLivePhotos(self)
//                        }
//                        else {
//                            print("Capture Session: -Error- in progress live photo capture count is less than 0");
//                        }
//                    }
//                }
//            }, completed: { [unowned self] delegate in
//                // When the capture is complete, remove a reference to the photo capture delegate so it can be deallocated.
//                self.sessionQueue.async { [unowned self] in
//                    self.inProgressPhotoCaptureDelegates[delegate.requestedPhotoSettings.uniqueID] = nil
//                }
//
//                DispatchQueue.main.async {
//                    if let data = delegate.photoData {
//                        self.photoCapturingDelegate?.captureSession(self, didCapturePhotoData: data, with: delegate.requestedPhotoSettings)
//                    }
//                    else if let error = delegate.processError {
//                        self.photoCapturingDelegate?.captureSession(self, didFailCapturingPhotoWith: error)
//                    }
//                }
//            })
//
//            photoCaptureDelegate.savesPhotoToLibrary = saveToPhotoLibrary
//
//            /*
//                The Photo Output keeps a weak reference to the photo capture delegate so we store it in an array to maintain a strong reference to this object until the capture is completed.
//             */
//            self.inProgressPhotoCaptureDelegates[photoCaptureDelegate.requestedPhotoSettings.uniqueID] = photoCaptureDelegate
//            self.photoOutput.capturePhoto(with: photoSettings, delegate: photoCaptureDelegate)
//        }
//    }
//}
//
//// MARK: - Recording Videos Extension
//extension RACaptureSession {
//
//    func startVideoRecording(saveToPhotoLibrary: Bool) {
//
//        guard let movieFileOutput = self.videoFileOutput else {
//            return print("Capture Session: trying to record a video but no movie file output is set")
//        }
//
//        guard let previewLayer = self.previewLayer else {
//            return print("Capture Session: trying to record a video but no preview layer is set")
//        }
//
//        /*
//            Retrieve the video preview layer's video orientation on the main queue before entering the session queue. We do this to ensure UI elements are accessed on the main thread and session configuration is done on the session queue.
//         */
//        let videoPreviewLayerOrientation = previewLayer.connection?.videoOrientation
//        sessionQueue.async { [weak self] in
//            guard let strongSelf = self else {
//                return
//            }
//            // If already recording do nothing
//            guard movieFileOutput.isRecording == false else {
//                return print("Capture Session: trying to record a video but there is one already being recorded")
//            }
//            // Update the orientation on the movie file output video connection before starting recording.
//            let movieFileOutputConnection = strongSelf.videoFileOutput?.connection(with: AVMediaType.video)
//            movieFileOutputConnection?.videoOrientation = videoPreviewLayerOrientation!
//            // Start recording to a temporary file.
//            let outputFileName = NSUUID().uuidString
//            let outputURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent(outputFileName).appendingPathExtension("mov")
//            // Create a recording delegate
//            let recordingDelegate = RAVideoCaptureDelegate(didStart: {
//                DispatchQueue.main.async { [weak self] in
//                    self?.videoRecordingDelegate?.captureSessionDidStartVideoRecording(self!)
//                }
//            }, didFinish: { (delegate) in
//                // We need to remove reference to the delegate so it can be deallocated
//                self?.sessionQueue.async {
//                    self?.videoCaptureDelegate = nil
//                }
//                DispatchQueue.main.async { [weak self] in
//                    if delegate.isBeingCancelled {
//                        self?.videoRecordingDelegate?.captureSessionDidCancelVideoRecording(self!)
//                    }
//                    else {
//                        self?.videoRecordingDelegate?.captureSessionDid(self!, didFinishVideoRecording: outputURL)
//                    }
//                }
//
//            }, didFail: { (delegate, error) in
//                // We need to remove reference to the delegate so it can be deallocated
//                self?.sessionQueue.async {
//                    self?.videoCaptureDelegate = nil
//                }
//                DispatchQueue.main.async { [weak self] in
//                    if delegate.recordingWasInterrupted {
//                        self?.videoRecordingDelegate?.captureSessionDid(self!, didInterruptVideoRecording: outputURL, reason: error)
//                    }
//                    else {
//                        self?.videoRecordingDelegate?.captureSessionDid(self!, didFailVideoRecording: error)
//                    }
//                }
//            })
//            recordingDelegate.savesVideoToLibrary = saveToPhotoLibrary
//            // Start recording
//            movieFileOutput.startRecording(to: outputURL, recordingDelegate: recordingDelegate)
//            strongSelf.videoCaptureDelegate = recordingDelegate
//        }
//    }
//
//    /*
//        If there is any recording in progress it will be stopped
//            - cancel: Bool,  if true, recorded file will be deleted and corresponding delegate method will be called.
//     */
//    func stopVideoRecording(cancel: Bool = false) {
//
//        guard let movieFileOutput = self.videoFileOutput else {
//            return print("Capture Session: trying to stop a video recording but no movie file output is set")
//        }
//
//        sessionQueue.async { [capturedSelf = self] in
//
//            guard movieFileOutput.isRecording else {
//                return print("Capture Session: trying to stop a video recording but no recording is in progress")
//            }
//
//            guard let recordingDelegate = capturedSelf.videoCaptureDelegate else {
//                fatalError("Capture Session: trying to stop a video recording but video capture delegate is nil")
//            }
//
//            recordingDelegate.isBeingCancelled = cancel
//            movieFileOutput.stopRecording()
//        }
//    }
//}
